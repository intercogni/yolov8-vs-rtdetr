{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8 Accuracy vs. Inference Time Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyzes the trade-off between accuracy (mAP) and inference time for different YOLOv8 models (nano, small, medium, large, xlarge) using the 'Food Image Segmentation' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics (if not already installed)\n",
    "!pip install ultralytics\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Models and Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'yolov8n': 'yolov8n.pt',  # nano\n",
    "    'yolov8s': 'yolov8s.pt',  # small\n",
    "    'yolov8m': 'yolov8m.pt',  # medium\n",
    "    'yolov8l': 'yolov8l.pt',  # large\n",
    "    'yolov8x': 'yolov8x.pt'   # xlarge\n",
    "}\n",
    "\n",
    "data_yaml_path = 'data/yolov8/data.yaml'\n",
    "imgsz = 640 # Image size for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data = []\n",
    "\n",
    "for name, weights_path in models.items():\n",
    "    print(f\"\\nEvaluating {name}...\")\n",
    "    try:\n",
    "        # Load a pretrained YOLOv8 model\n",
    "        model = YOLO(weights_path)\n",
    "\n",
    "        # Validate the model on the dataset\n",
    "        # The 'metrics' object contains mAP50-95, mAP50, and inference time\n",
    "        metrics = model.val(data=data_yaml_path, imgsz=imgsz, conf=0.25, iou=0.6, device=0 if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Extract relevant metrics\n",
    "        map50_95 = metrics.box.map # mAP50-95\n",
    "        map50 = metrics.box.map50 # mAP50\n",
    "        inference_time_ms = metrics.speed['inference'] # Inference time in ms\n",
    "\n",
    "        results_data.append({\n",
    "            'Model': name,\n",
    "            'mAP50-95': map50_95,\n",
    "            'mAP50': map50,\n",
    "            'Inference Time (ms)': inference_time_ms\n",
    "        })\n",
    "        del model # Clear model from memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {name}: {e}\")\n",
    "        results_data.append({\n",
    "            'Model': name,\n",
    "            'mAP50-95': None,\n",
    "            'mAP50': None,\n",
    "            'Inference Time (ms)': None\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results_data)\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(\n",
    "    data=df_results,\n",
    "    x='Inference Time (ms)',\n",
    "    y='mAP50-95',\n",
    "    hue='Model',\n",
    "    s=200, # Size of points\n",
    "    style='Model', # Different markers for different models\n",
    "    markers=True\n",
    ")\n",
    "\n",
    "# Add model names next to points\n",
    "for i, row in df_results.iterrows():\n",
    "    plt.text(row['Inference Time (ms)'] + 0.5, row['mAP50-95'], row['Model'], ha='left', va='center', fontsize=10)\n",
    "\n",
    "plt.title('YOLOv8 Accuracy (mAP50-95) vs. Inference Time')\n",
    "plt.xlabel('End-to-end Latency T4 TensorRT FP16 (ms)') # Matching the provided image's x-axis label\n",
    "plt.ylabel('COCO AP (%)') # Matching the provided image's y-axis label\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on the generated plot and evaluation results, we can observe the following:\n",
    "\n",
    "- **Trade-off**: There is a clear trade-off between model accuracy (mAP) and inference time. Generally, larger models (e.g., yolov8x) achieve higher accuracy but require more inference time, while smaller models (e.g., yolov8n) are faster but less accurate.\n",
    "\n",
    "- **Model Performance**: \n",
    "    - `yolov8n` (nano) is the fastest but has the lowest mAP.\n",
    "    - As we move from `yolov8s` to `yolov8m`, `yolov8l`, and `yolov8x`, the mAP generally increases, but so does the inference time.\n",
    "\n",
    "- **Choosing a Model**: The choice of model depends on the specific application's requirements for speed versus accuracy. For real-time applications where speed is critical, `yolov8n` or `yolov8s` might be preferred. For applications requiring higher accuracy, `yolov8l` or `yolov8x` would be more suitable, provided the inference time is acceptable.\n",
    "\n",
    "This analysis provides a quantitative understanding of how different YOLOv8 model sizes perform on the given dataset, aiding in model selection for deployment.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
